{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Mask R-CNN Net for Object Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize device and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters of data\n",
    "BATCH_SIZE = 2\n",
    "IMAGE_SIZE = [600, 600]\n",
    "\n",
    "# define device\n",
    "device = torch.device('cuda') if torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``IMAGE_SIZE = [Width, Height]`` are the dimensions of the image used for training. All images during the training processes will be resized to this size.\n",
    "\n",
    "``BATCH_SIZE`` is the number of images that will be used for each iteration of the training.\n",
    "\n",
    "``BATCH_SIZE * Width * Height`` will be proportional to the memory requirement of the training. Depending on your hardware, it might be necessary to use a smaller BATCH_SIZE or image size to avoid out-of-memory problems.\n",
    "\n",
    "Note that since there is only a single image size, the net once trained is likely to be limited to work with only images of this size. In most cases what is necessary is to change the size of each training batch.\n",
    "\n",
    "``device`` is automatically set the device where the net will run (GPU or CPU), in practice training without a strong GPU is extremely slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all images in the dataset\n",
    "train_dir = 'LabPicsChemistry/Train'\n",
    "\n",
    "imgs = []\n",
    "for pth in os.listdir(train_dir):\n",
    "    imgs.append(train_dir + '/' + pth + '//')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``train_dir`` is the LabPics V2 dataset train folder.\n",
    "\n",
    "``imgs`` is the list of all images in the trainset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a data loader function is created that will allow for loading a batch of random images and their data for training. The data will contain the image and and masks of all the objects in the image. Each mask will be saved as a black-white (0/1) image.\n",
    "\n",
    "These masks are images the same size as the RGB image where the region of the object instances is marked 1 and the rest are marked 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# dataloader\n",
    "def load_data():\n",
    "  \n",
    "    batch_imgs = []\n",
    "    batch_data = []\n",
    "\n",
    "    # loop over images in the batch  \n",
    "    for i in range(BATCH_SIZE):\n",
    "        \n",
    "        # pick a random image from the list (idx)\n",
    "        idx = random.randint(0, len(imgs) - 1)\n",
    "        \n",
    "        # load the image\n",
    "        img = cv2.imread(os.path.join(imgs[idx], 'Image.jpg'))\n",
    "        \n",
    "        # resize image to the standard size (IMAGE_SIZE)\n",
    "        img = cv2.resize(img, IMAGE_SIZE, cv2.INTER_LINEAR)\n",
    "        \n",
    "        # get subfolder where the vessel instances map is stored\n",
    "        mask_dir = os.path.join(imgs[idx], 'Vessels')\n",
    "        masks = []\n",
    "        \n",
    "        # loop over name of masks got from their directory\n",
    "        for msk_name in os.listdir(mask_dir):\n",
    "            \n",
    "            # read the masks\n",
    "            ves_mask = cv2.imread(mask_dir + '/' + msk_name, 0)\n",
    "            \n",
    "            # store mask in 0–255 format and is converted to 0–1 format\n",
    "            ves_mask = (ves_mask > 0).astype(np.uint8) \n",
    "            \n",
    "            # resize mask to the standard image size\n",
    "            ves_mask = cv2.resize(ves_mask, IMAGE_SIZE, cv2.INTER_NEAREST)\n",
    "            \n",
    "            # add mask to the list\n",
    "            masks.append(ves_mask)\n",
    "        \n",
    "        num_objs = len(masks)\n",
    "        \n",
    "        # test the number of objects on the image\n",
    "        if num_objs == 0: \n",
    "            return load_data()\n",
    "        \n",
    "        boxes = torch.zeros([num_objs, 4], dtype=torch.float32)\n",
    "        \n",
    "        # use the masks to generate a bounding box for each object\n",
    "        for i in range(num_objs):\n",
    "\n",
    "            # x, y: are the top coordinate of the bounding box\n",
    "            # w, h: are the width and height of the bounding box\n",
    "            x, y, w, h = cv2.boundingRect(masks[i])\n",
    "\n",
    "            # mask RCNN bounding box format demands the top left and bottom right\n",
    "            # coordinate of the box which is given by: [x, y, x + w, y + h]\n",
    "            boxes[i] = torch.tensor([x, y, x + w, y + h])\n",
    "        \n",
    "        # convert data into a tensor\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        img = torch.as_tensor(img, dtype=torch.float32)\n",
    "        \n",
    "        # stack all the information about the image into one dictionary\n",
    "        data = {}\n",
    "        data['boxes'] = boxes       \n",
    "        data['masks'] = masks\n",
    "        \n",
    "        # pick ones for everything to take the class of all the objects to be the same (1)\n",
    "        data['labels'] =  torch.ones((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # add data to the lists\n",
    "        batch_imgs.append(img)\n",
    "        batch_data.append(data)  \n",
    "  \n",
    "  # load the image data into the training batch and convert it to PyTorch format\n",
    "  batch_imgs = torch.stack([torch.as_tensor(d) for d in batch_imgs], 0)\n",
    "  batch_imgs = batch_imgs.swapaxes(1, 3).swapaxes(2, 3)\n",
    "  \n",
    "  return batch_imags, batch_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Now start building the net. First, load a mask RCNN model that was already pretrained on the COCO dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load pretreined model\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretrained model that uses existing knowledge can learn new tasks and datasets much faster than a model that was not trained before."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The COCO dataset contains over 100 classes. In this project, it is only needed to get two classes. There will be a change of the final layers of the net to predict two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# get a number of input features in the head\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features \n",
    "\n",
    "# replace standard bounding box predictor with Fast-RCNN (2 classes) \n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)\n",
    "\n",
    "# load the model to the training device GPU or CPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# define the optimizer to determine the way the net weights will be changed during training\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# set the model to train mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# main training loop\n",
    "for i in range(10001):\n",
    "   \n",
    "    # load the data using the data loader function\n",
    "    images, targets = load_data()\n",
    "   \n",
    "    # load the data into the training device (CPU/GPU)\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "   \n",
    "    # set gradients of all optimized tensors to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # take the images and data and run it through our neural net to get the loss\n",
    "    loss_dict = model(images, targets)\n",
    "\n",
    "    # loss is composed of several parts: class loss, bounding box loss, and mask loss; \n",
    "    # all of these parts are summed together to get the total loss as a single number\n",
    "    losses = sum(loss for loss in loss_dict.values())\n",
    "   \n",
    "    # update the neural net weights using backpropagation\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print out losses\n",
    "    print(i, 'loss:', losses.item())\n",
    "   \n",
    "    # save the trained model once every 500 steps\n",
    "    if i % 200 == 0:\n",
    "        torch.save(model.state_dict(), str(i) + '.torch')\n",
    "        print('Save model to:', str(i) + '.torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is finished the model has to be tested.\n",
    "\n",
    "The script is similar to the training script. The first part is simply loading the net as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# model for testing\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  \n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True) \n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features \n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)\n",
    "\n",
    "# the only difference is to load the saved model, \n",
    "# and set the model to evaluation state\n",
    "model.load_state_dict(torch.load('10000.torch'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# a single image loaded, resized to standard size, and converted to PyTorch format\n",
    "images = cv2.imread(img_path)\n",
    "images = cv2.resize(images, IMAGE_SIZE, cv2.INTER_LINEAR)\n",
    "images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)\n",
    "images = images.swapaxes(1, 3).swapaxes(2, 3)\n",
    "images = list(image.to(device) for image in images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# run the image through the net\n",
    "with torch.no_grad():\n",
    "    pred = model(images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs the image through the net and gets a prediction for the object in the image. Note we are not training the net, so we do not need to collect gradient (no_grad) this makes the net run much faster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is composed of several parts: “masks” which corresponds to the mask (regions) of every object in the image. “Scores” correspond to how likely the predicted mask is correct. In addition, there is the predicted bounding box and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# get image and its copy\n",
    "im = images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)\n",
    "im2 = im.copy()\n",
    "\n",
    "# go over all the predictions \n",
    "# and display only those objects with “scores” larger than 0.8\n",
    "for i in range(len(pred[0]['masks'])):\n",
    "    \n",
    "    msk = pred[0]['masks'][i, 0].detach().cpu().numpy()\n",
    "    scr = pred[0]['scores'][i].detach().cpu().numpy()\n",
    "    \n",
    "    if scr > 0.8:\n",
    "        im2[:, :, 0][msk > 0.5] = random.randint(0, 255)\n",
    "        im2[:, :, 1][msk > 0.5] = random.randint(0, 255)\n",
    "        im2[:, :, 2][msk > 0.5] = random.randint(0, 255)\n",
    "\n",
    "cv2.imshow(str(scr), np.hstack([im, im2]))\n",
    "cv2.waitKey()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the predicted object ‘masks’ are saved as a matrix in the same size as the image with each pixel having a value that corresponds to how likely it is part of the object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only pixels which values larger than 0.5 are likely to be part of the objects. This is displayed by marking these pixels with a different random color for each object"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
